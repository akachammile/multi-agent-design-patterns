# Runnables â€” LangChain çš„æ ¸å¿ƒåè®®

> `Runnable` æ˜¯ LangChain çš„**ç»å¯¹æ ¸å¿ƒ**ï¼Œ**ä¸”æ²¡æœ‰ä¹‹ä¸€**ã€‚
> æ— è®ºæ˜¯ Modelã€Toolã€Prompt è¿˜æ˜¯ Parserï¼Œæ‰€æœ‰ç»„ä»¶éƒ½å®ç°äº† `Runnable` æ¥å£ã€‚
> LangChain è¿™æ ·è®¾è®¡ï¼Œæˆ‘ä¼°è®¡æ˜¯æœ‰ä»¥ä¸‹åŸå› 
>
> 1ï¼Œä¸ºäº†ä¸åŒçš„æƒ…å†µä¸‹ï¼Œä¾æ—§èƒ½å®ç°ç»Ÿä¸€çš„è°ƒç”¨æ–¹æ³•ï¼Œæ˜¯é«˜åº¦æŠ½è±¡çš„è®¾è®¡ã€‚
>
> 2ï¼Œè¿™é‡Œåæ§½ä¸€ä¸‹ï¼Œæ„Ÿè§‰æ˜¯æ²¡æœ‰å¿…è¦çš„ä¸œè¥¿ï¼Œè®¾è®¡æœ‰ç‚¹è¿‡äºå¤æ‚

---

## ğŸ“¦ `runnables/base.py` æ ¸å¿ƒç±»

```
Runnable (ABC, Generic[Input, Output])        â† åŸºç±»
    â”‚
    â”œâ”€â”€ RunnableSerializable                  â† å¯åºåˆ—åŒ–çš„ Runnable
    â”‚
    â”œâ”€â”€ RunnableSequence                      â† ä¸²è¡Œé“¾ï¼ˆA | B | Cï¼‰
    â”‚
    â”œâ”€â”€ RunnableParallel                      â† å¹¶è¡Œé“¾ï¼ˆ{"a": A, "b": B}ï¼‰
    â”‚
    â”œâ”€â”€ RunnableGenerator                     â† ç”Ÿæˆå™¨å‡½æ•°åŒ…è£…å™¨
    â”‚
    â””â”€â”€ RunnableLambda                        â† æ™®é€šå‡½æ•°åŒ…è£…å™¨
```



---

## ğŸŒŸ ç¬¬ä¸€éƒ¨åˆ†ï¼šRunnable æ¥å£å®šä¹‰

### æ ¸å¿ƒæ–¹æ³•ï¼ˆ4 ç±»ï¼‰

| åˆ†ç±» | æ–¹æ³• | è¯´æ˜ |
| :--- | :--- | :--- |
| **æ‰§è¡Œ** | `invoke` / `ainvoke` | å•æ¬¡è°ƒç”¨ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰ |
| | `stream` / `astream` | æµå¼è¾“å‡º |
| | `batch` / `abatch` | æ‰¹é‡å¹¶å‘ |
| | `transform` / `atransform` | æµå¼è¾“å…¥ â†’ æµå¼è¾“å‡º |
| **ç»„åˆ** | `__or__` (`\|`) | ä¸²è¡Œç»„åˆï¼š`A \| B \| C` â†’ `RunnableSequence` |
| | `pipe()` | åŒä¸Šï¼Œæ–¹æ³•è°ƒç”¨ç‰ˆ |
| | `pick()` | ä» dict è¾“å‡ºä¸­é€‰ key |
| | `assign()` | ç»™ dict è¾“å‡ºæ·»åŠ æ–° key |
| **è£…é¥°** | `bind()` | ç»‘å®šé»˜è®¤å‚æ•°ï¼ˆAgent ç»‘å®šå·¥å…·çš„åŸºç¡€ï¼‰ |
| | `with_config()` | ç»‘å®šè¿è¡Œæ—¶é…ç½® |
| | `with_retry()` | å¤±è´¥è‡ªåŠ¨é‡è¯• |
| | `with_fallbacks()` | å¤±è´¥åˆ‡æ¢å¤‡ç”¨æ–¹æ¡ˆ |
| | `with_listeners()` | æ·»åŠ ç”Ÿå‘½å‘¨æœŸé’©å­ |
| **å†…çœ** | `input_schema` / `output_schema` | è·å–è¾“å…¥/è¾“å‡ºçš„ Pydantic Schema |
| | `get_graph()` | è·å–å›¾ç»“æ„ï¼ˆå¯è§†åŒ–ç”¨ï¼‰ |

### è®¾è®¡åˆè¡·

LangChain æ—©æœŸå„ç»„ä»¶è°ƒç”¨æ–¹å¼ä¸ç»Ÿä¸€
`Runnable` çš„å‡ºç°å°†**æ‰€æœ‰ç»„ä»¶ç»Ÿä¸€ä¸ºåŒä¸€å¥—æ–¹æ¡ˆ**ï¼Œè§£å†³äº†ä»¥ä¸‹é—®é¢˜ï¼š

Runnable çš„æºç ä¸ºä»¥ä¸‹ï¼Œä½†æ˜¯å¤ªé•¿äº†ï¼Œè¿™é‡ŒæŒ‰ä¸‹ä¸è¡¨ï¼Œåç»­å†è¯´

```python
class Runnable(ABC, Generic[Input, Output]):
    """A unit of work that can be invoked, batched, streamed, transformed and composed.

    Key Methods
    ===========

    - `invoke`/`ainvoke`: Transforms a single input into an output.
    - `batch`/`abatch`: Efficiently transforms multiple inputs into outputs.
    - `stream`/`astream`: Streams output from a single input as it's produced.
    - `astream_log`: Streams output and selected intermediate results from an
        input.
    name: str | None
    """The name of the `Runnable`. Used for debugging and tracing."""
```



1. **è°ƒç”¨æ–¹æ³•çš„ç»Ÿä¸€** â†’ ç»Ÿä¸€ `invoke`/`stream`/`batch`

2. **æ³›å‹æ¨æ–­**

   ```python
   @property
       def InputType(self) -> type[Input]:  # noqa: N802
           """Input type.
   
           The type of input this `Runnable` accepts specified as a type annotation.
   
           Raises:
               TypeError: If the input type cannot be inferred.
           """
           # First loop through all parent classes and if any of them is
           # a Pydantic model, we will pick up the generic parameterization
           # from that model via the __pydantic_generic_metadata__ attribute.
           for base in self.__class__.mro():
               if hasattr(base, "__pydantic_generic_metadata__"):
                   metadata = base.__pydantic_generic_metadata__
                   if (
                       "args" in metadata
                       and len(metadata["args"]) == _RUNNABLE_GENERIC_NUM_ARGS
                   ):
                       return cast("type[Input]", metadata["args"][0])
   
           # If we didn't find a Pydantic model in the parent classes,
           # then loop through __orig_bases__. This corresponds to
           # Runnables that are not pydantic models.
           for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]
               type_args = get_args(cls)
               if type_args and len(type_args) == _RUNNABLE_GENERIC_NUM_ARGS:
                   return cast("type[Input]", type_args[0])
   
           msg = (
               f"Runnable {self.get_name()} doesn't have an inferable InputType. "
               "Override the InputType property to specify the input type."
           )
           raise TypeError(msg)
   
       @property
       def OutputType(self) -> type[Output]:  # noqa: N802
           """Output Type.
   
           The type of output this `Runnable` produces specified as a type annotation.
   
           Raises:
               TypeError: If the output type cannot be inferred.
           """
           # First loop through bases -- this will help generic
           # any pydantic models.
           for base in self.__class__.mro():
               if hasattr(base, "__pydantic_generic_metadata__"):
                   metadata = base.__pydantic_generic_metadata__
                   if (
                       "args" in metadata
                       and len(metadata["args"]) == _RUNNABLE_GENERIC_NUM_ARGS
                   ):
                       return cast("type[Output]", metadata["args"][1])
   
           for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]
               type_args = get_args(cls)
               if type_args and len(type_args) == _RUNNABLE_GENERIC_NUM_ARGS:
                   return cast("type[Output]", type_args[1])
   
           msg = (
               f"Runnable {self.get_name()} doesn't have an inferable OutputType. "
               "Override the OutputType property to specify the output type."
           )
           raise TypeError(msg)
   ```

   

3. **ç»„åˆå¼çš„æ‰§è¡Œ** â†’ `|` å…¶åº•å±‚é‡å†™äº† `__or__` æ–¹æ³•

   ```python
   def __or__(
           self,
           other: Runnable[Any, Other]
           | Callable[[Iterator[Any]], Iterator[Other]]
           | Callable[[AsyncIterator[Any]], AsyncIterator[Other]]
           | Callable[[Any], Other]
           | Mapping[str, Runnable[Any, Other] | Callable[[Any], Other] | Any],
       ) -> RunnableSerializable[Input, Other]:
           """Runnable "or" operator.
   
           Compose this `Runnable` with another object to create a
           `RunnableSequence`.
   
           Args:
               other: Another `Runnable` or a `Runnable`-like object.
   
           Returns:
               A new `Runnable`.
           """
           return RunnableSequence(self, coerce_to_runnable(other))
   ```

   è¿™ä½¿å¾—å°è£…å‡ºä¸€ä¸ªSequenceåºåˆ—ï¼Œå°†ä¸Šä¸€æ­¥çš„ç»“æœä½œä¸ºä¸‹ä¸€æ­¥ç»„ä»¶çš„è¾“å‡ºï¼Œå½“å½¢æˆäº† `langchain` çš„ç»„ä»¶ä¹‹æ—¶ä¾‹å¦‚ä»¥ä¸‹ä¾‹å­ã€‚

   ```python
   chain = prompt | model    # è¿™é‡Œå‡è®¾ prompt ä¸ºchatpromptä¹‹ç±»çš„å¯¹è±¡çš„æ—¶å€™ï¼Œ ç”±äº Runnable é‡å†™äº† __or__ é­”æœ¯æ–¹æ³•
   chain = prompt.__or__(model) # é‚£ä¹ˆä»¥ä¸Šçš„åŠ¨ä½œå°±å˜æˆäº†è¿™æ ·å­ï¼Œä½¿å¾—å…¶è¿”å›äº† RunnableSequence å¯¹è±¡ï¼Œå½“éœ€è¦ä¸²è¡Œå…¶ä»–ç»„ä»¶çš„æ—¶å€™ï¼Œé‡å¤ä»¥ä¸Šçš„æ“ä½œå³å¯
   ```

   **è¿™ä¾¿æ˜¯`langchain` æœ€åˆä¸²è”ç»„ä»¶çš„æ ¸å¿ƒæ–¹å¼ã€‚**

   å½“ç„¶è¿™é‡Œåˆå‡ºç°äº†ä¸€ä¸ªç¼ºç‚¹ï¼Œè¿™å°±è¦å›åˆ° `Agent` çš„å®šä¹‰ä¸Šå»äº†ã€‚

   ä»€ä¹ˆæ˜¯ `Agent` , å³ ***An LLM agent runs tools in a loop to achieve a goal***

   key point is ***the loop*** ä½†æ˜¯å…¶ä¸²è¡Œçš„æ–¹å¼æ„å‘³ç€è¿™æ— æ³•è¿›è¡Œè‡ªæ£€å’Œå¾ªç¯ï¼Œè¿™å°±ä¸ç¬¦åˆå…¶å®šä¹‰

   å› æ­¤ `langchain` ä¾¿æ¨å‡ºäº† `langgraph`  ä»¥åŠåç»­çš„å¤§æ”¹ç‰ˆï¼Œ å½“ç„¶å°±è¿™æ˜¯å…¶ä»–æ¨¡å—è¦è¯´çš„ä¸œè¥¿äº†ã€‚ 

   ** **

4. **å¼‚æ­¥/æµå¼é‡å¤å†™** â†’ åŸºç±»æä¾›é»˜è®¤å®ç°

5. **ç±»å‹ä¸é€æ˜** â†’ `input_schema`/`output_schema` è‡ªåŠ¨æ¨æ–­

---

## ğŸŒŸ ç¬¬äºŒéƒ¨åˆ†ï¼šç»„åˆåºåˆ—

### `RunnableSequence` â€” ä¸²è¡Œé“¾ï¼ˆæœ€å¸¸ç”¨ï¼‰

```python
chain = prompt | model | parser
# å†…éƒ¨ï¼šRunnableSequence(first=prompt, middle=[model], last=parser)
# æ‰§è¡Œï¼šprompt çš„è¾“å‡º â†’ model çš„è¾“å…¥ â†’ parser çš„è¾“å…¥
```

`|` æ“ä½œç¬¦å°±æ˜¯ `__or__` é‡è½½ï¼Œè¿”å›ä¸€ä¸ª `RunnableSequence` å¯¹è±¡ã€‚

### `RunnableParallel` â€” å¹¶è¡Œé“¾

```python
chain = prompt | {"answer": model, "source": retriever}
# å­—å…¸å­—é¢é‡è‡ªåŠ¨å˜æˆ RunnableParallel
# åŒä¸€ä¸ªè¾“å…¥åŒæ—¶å‘ç»™ model å’Œ retrieverï¼Œç»“æœåˆæˆä¸€ä¸ª dict
```

### `RunnableLambda` â€” æ™®é€šå‡½æ•°åŒ…è£…å™¨

```python
add_one = RunnableLambda(lambda x: x + 1)
chain = add_one | model  # æ™®é€šå‡½æ•°ä¹Ÿèƒ½å‚ä¸é“¾å¼è°ƒç”¨
```

### `RunnableGenerator` â€” ç”Ÿæˆå™¨åŒ…è£…å™¨

```python
def stream_words(input):
    for word in input.split():
        yield word

streamer = RunnableGenerator(stream_words)  # æ”¯æŒæµå¼
```

---

## ğŸŒŸ ç¬¬ä¸‰éƒ¨åˆ†ï¼šaliment of Agent 

### `bind()` â€” Agent ç»‘å®šå·¥å…·çš„åŸºç¡€

```python
model_with_tools = model.bind_tools(tools)
# åº•å±‚å°±æ˜¯ bind()ï¼Œå°†å·¥å…· schema ä½œä¸ºé»˜è®¤å‚æ•°ç»‘å®šåˆ°æ¨¡å‹ä¸Š
```

### `with_retry()` + `with_fallbacks()` â€” å®¹é”™æœºåˆ¶

```python
safe_model = model.with_retry(stop_after_attempt=3)
safe_model = gpt4.with_fallbacks([gpt35, local_model])
```

### LCEL çš„ç°çŠ¶ï¼ˆ2025ï¼‰

LCELï¼ˆ`A | B | C` è¯­æ³•ï¼‰æ²¡æœ‰è¢«åºŸå¼ƒï¼Œä½†å·²**ä»å°å‰é€€åˆ°å°å**ï¼š

| å±‚çº§ | ç”¨ä»€ä¹ˆ | è¯´æ˜ |
| :--- | :--- | :--- |
| **Agent ç¼–æ’å±‚** | **LangGraph** | çŠ¶æ€æœº + å›¾ï¼ˆæ”¯æŒå¾ªç¯å’Œåˆ†æ”¯ï¼‰ |
| **å•æ­¥æ‰§è¡Œå±‚** | **LCEL** | åœ¨ LangGraph èŠ‚ç‚¹å†…éƒ¨ `prompt \| model \| parser` |

LCEL é€‚åˆçº¿æ€§é“¾ï¼Œä½† Agent éœ€è¦å¾ªç¯ï¼ˆæ€è€ƒâ†’è¡ŒåŠ¨â†’è§‚å¯Ÿâ†’å†æ€è€ƒï¼‰ï¼Œè¿™éœ€è¦ LangGraphã€‚

---

## ğŸ”— ç›¸å…³æºç 

- `langchain_core/runnables/base.py` â€” `Runnable` åŠæ‰€æœ‰ç»„åˆåŸè¯­çš„å®šä¹‰
- `langchain_core/runnables/config.py` â€” `RunnableConfig` è¿è¡Œæ—¶é…ç½®
