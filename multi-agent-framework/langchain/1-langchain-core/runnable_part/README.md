# Runnables â€” LangChain çš„æ ¸å¿ƒåè®®

> `Runnable` æ˜¯ LangChain çš„**ç»å¯¹æ ¸å¿ƒ**ï¼Œ**ä¸”æ²¡æœ‰ä¹‹ä¸€**ã€‚
> æ— è®ºæ˜¯ Modelã€Toolã€Prompt è¿˜æ˜¯ Parserï¼Œæ‰€æœ‰ç»„ä»¶éƒ½å®žçŽ°äº† `Runnable` æŽ¥å£ã€‚
> LangChain è¿™æ ·è®¾è®¡ï¼Œæˆ‘ä¼°è®¡æ˜¯æœ‰ä»¥ä¸‹åŽŸå› 
>
> 1ï¼Œä¸ºäº†ä¸åŒçš„æƒ…å†µä¸‹ï¼Œä¾æ—§èƒ½å®žçŽ°ç»Ÿä¸€çš„è°ƒç”¨æ–¹æ³•ï¼Œæ˜¯é«˜åº¦æŠ½è±¡çš„è®¾è®¡ã€‚
>
> 2ï¼Œè¿™é‡Œåæ§½ä¸€ä¸‹ï¼Œæ„Ÿè§‰æ˜¯æ²¡æœ‰å¿…è¦çš„ä¸œè¥¿ï¼Œè®¾è®¡æœ‰ç‚¹è¿‡äºŽå¤æ‚

---

## ðŸ“¦ `runnables/base.py` æ ¸å¿ƒç±»

```
Runnable (ABC, Generic[Input, Output])        â† åŸºç±»
    â”‚
    â”œâ”€â”€ RunnableSerializable                  â† å¯åºåˆ—åŒ–çš„ Runnable
    â”‚
    â”œâ”€â”€ RunnableSequence                      â† ä¸²è¡Œé“¾ï¼ˆA | B | Cï¼‰
    â”‚
    â”œâ”€â”€ RunnableParallel                      â† å¹¶è¡Œé“¾ï¼ˆ{"a": A, "b": B}ï¼‰
    â”‚
    â”œâ”€â”€ RunnableGenerator                     â† ç”Ÿæˆå™¨å‡½æ•°åŒ…è£…å™¨
    â”‚
    â””â”€â”€ RunnableLambda                        â† æ™®é€šå‡½æ•°åŒ…è£…å™¨
```



---

## ðŸŒŸ ç¬¬ä¸€éƒ¨åˆ†ï¼šRunnable æŽ¥å£å®šä¹‰

### æ ¸å¿ƒæ–¹æ³•ï¼ˆ4 ç±»ï¼‰

| åˆ†ç±» | æ–¹æ³• | è¯´æ˜Ž |
| :--- | :--- | :--- |
| **æ‰§è¡Œ** | `invoke` / `ainvoke` | å•æ¬¡è°ƒç”¨ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰ |
| | `stream` / `astream` | æµå¼è¾“å‡º |
| | `batch` / `abatch` | æ‰¹é‡å¹¶å‘ |
| | `transform` / `atransform` | æµå¼è¾“å…¥ â†’ æµå¼è¾“å‡º |
| **ç»„åˆ** | `__or__` (`\|`) | ä¸²è¡Œç»„åˆï¼š`A \| B \| C` â†’ `RunnableSequence` |
| | `pipe()` | åŒä¸Šï¼Œæ–¹æ³•è°ƒç”¨ç‰ˆ |
| | `pick()` | ä»Ž dict è¾“å‡ºä¸­é€‰ key |
| | `assign()` | ç»™ dict è¾“å‡ºæ·»åŠ æ–° key |
| **è£…é¥°** | `bind()` | ç»‘å®šé»˜è®¤å‚æ•°ï¼ˆAgent ç»‘å®šå·¥å…·çš„åŸºç¡€ï¼‰ |
| | `with_config()` | ç»‘å®šè¿è¡Œæ—¶é…ç½® |
| | `with_retry()` | å¤±è´¥è‡ªåŠ¨é‡è¯• |
| | `with_fallbacks()` | å¤±è´¥åˆ‡æ¢å¤‡ç”¨æ–¹æ¡ˆ |
| | `with_listeners()` | æ·»åŠ ç”Ÿå‘½å‘¨æœŸé’©å­ |
| **å†…çœ** | `input_schema` / `output_schema` | èŽ·å–è¾“å…¥/è¾“å‡ºçš„ Pydantic Schema |
| | `get_graph()` | èŽ·å–å›¾ç»“æž„ï¼ˆå¯è§†åŒ–ç”¨ï¼‰ |

### è®¾è®¡åˆè¡·

LangChain æ—©æœŸå„ç»„ä»¶è°ƒç”¨æ–¹å¼ä¸ç»Ÿä¸€
`Runnable` çš„å‡ºçŽ°å°†**æ‰€æœ‰ç»„ä»¶ç»Ÿä¸€ä¸ºåŒä¸€å¥—æ–¹æ¡ˆ**ï¼Œè§£å†³äº†ä»¥ä¸‹é—®é¢˜ï¼š

Runnable çš„æºç ä¸ºä»¥ä¸‹ï¼Œä½†æ˜¯å¤ªé•¿äº†ï¼Œè¿™é‡ŒæŒ‰ä¸‹ä¸è¡¨ï¼ŒåŽç»­å†è¯´

```python
class Runnable(ABC, Generic[Input, Output]):
    """A unit of work that can be invoked, batched, streamed, transformed and composed.

    Key Methods
    ===========

    - `invoke`/`ainvoke`: Transforms a single input into an output.
    - `batch`/`abatch`: Efficiently transforms multiple inputs into outputs.
    - `stream`/`astream`: Streams output from a single input as it's produced.
    - `astream_log`: Streams output and selected intermediate results from an
        input.
    name: str | None
    """The name of the `Runnable`. Used for debugging and tracing."""
```



1. **è°ƒç”¨æ–¹æ³•çš„ç»Ÿä¸€** â†’ ç»Ÿä¸€ `invoke`/`stream`/`batch`

2. **æ³›åž‹æŽ¨æ–­**

   ```python
   @property
       def InputType(self) -> type[Input]:  # noqa: N802
           """Input type.
   
           The type of input this `Runnable` accepts specified as a type annotation.
   
           Raises:
               TypeError: If the input type cannot be inferred.
           """
           # First loop through all parent classes and if any of them is
           # a Pydantic model, we will pick up the generic parameterization
           # from that model via the __pydantic_generic_metadata__ attribute.
           for base in self.__class__.mro():
               if hasattr(base, "__pydantic_generic_metadata__"):
                   metadata = base.__pydantic_generic_metadata__
                   if (
                       "args" in metadata
                       and len(metadata["args"]) == _RUNNABLE_GENERIC_NUM_ARGS
                   ):
                       return cast("type[Input]", metadata["args"][0])
   
           # If we didn't find a Pydantic model in the parent classes,
           # then loop through __orig_bases__. This corresponds to
           # Runnables that are not pydantic models.
           for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]
               type_args = get_args(cls)
               if type_args and len(type_args) == _RUNNABLE_GENERIC_NUM_ARGS:
                   return cast("type[Input]", type_args[0])
   
           msg = (
               f"Runnable {self.get_name()} doesn't have an inferable InputType. "
               "Override the InputType property to specify the input type."
           )
           raise TypeError(msg)
   
       @property
       def OutputType(self) -> type[Output]:  # noqa: N802
           """Output Type.
   
           The type of output this `Runnable` produces specified as a type annotation.
   
           Raises:
               TypeError: If the output type cannot be inferred.
           """
           # First loop through bases -- this will help generic
           # any pydantic models.
           for base in self.__class__.mro():
               if hasattr(base, "__pydantic_generic_metadata__"):
                   metadata = base.__pydantic_generic_metadata__
                   if (
                       "args" in metadata
                       and len(metadata["args"]) == _RUNNABLE_GENERIC_NUM_ARGS
                   ):
                       return cast("type[Output]", metadata["args"][1])
   
           for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]
               type_args = get_args(cls)
               if type_args and len(type_args) == _RUNNABLE_GENERIC_NUM_ARGS:
                   return cast("type[Output]", type_args[1])
   
           msg = (
               f"Runnable {self.get_name()} doesn't have an inferable OutputType. "
               "Override the OutputType property to specify the output type."
           )
           raise TypeError(msg)
   ```

   

3. **ç»„åˆå¼çš„æ‰§è¡Œ** â†’ `|` å…¶åº•å±‚é‡å†™äº† `__or__` æ–¹æ³•

   ```python
   def __or__(
           self,
           other: Runnable[Any, Other]
           | Callable[[Iterator[Any]], Iterator[Other]]
           | Callable[[AsyncIterator[Any]], AsyncIterator[Other]]
           | Callable[[Any], Other]
           | Mapping[str, Runnable[Any, Other] | Callable[[Any], Other] | Any],
       ) -> RunnableSerializable[Input, Other]:
           """Runnable "or" operator.
   
           Compose this `Runnable` with another object to create a
           `RunnableSequence`.
   
           Args:
               other: Another `Runnable` or a `Runnable`-like object.
   
           Returns:
               A new `Runnable`.
           """
           return RunnableSequence(self, coerce_to_runnable(other))
   ```

   è¿™ä½¿å¾—å°è£…å‡ºä¸€ä¸ªSequenceåºåˆ—ï¼Œå°†ä¸Šä¸€æ­¥çš„ç»“æžœä½œä¸ºä¸‹ä¸€æ­¥ç»„ä»¶çš„è¾“å‡ºï¼Œå½“å½¢æˆäº† `langchain` çš„ç»„ä»¶ä¹‹æ—¶ä¾‹å¦‚ä»¥ä¸‹ä¾‹å­ã€‚

   ```python
   chain = prompt | model    # è¿™é‡Œå‡è®¾ prompt ä¸ºchatpromptä¹‹ç±»çš„å¯¹è±¡çš„æ—¶å€™ï¼Œ ç”±äºŽ Runnable é‡å†™äº† __or__ é­”æœ¯æ–¹æ³•
   chain = prompt.__or__(model) # é‚£ä¹ˆä»¥ä¸Šçš„åŠ¨ä½œå°±å˜æˆäº†è¿™æ ·å­ï¼Œä½¿å¾—å…¶è¿”å›žäº† RunnableSequence å¯¹è±¡ï¼Œå½“éœ€è¦ä¸²è¡Œå…¶ä»–ç»„ä»¶çš„æ—¶å€™ï¼Œé‡å¤ä»¥ä¸Šçš„æ“ä½œå³å¯
   ```

   **è¿™ä¾¿æ˜¯`langchain` æœ€åˆä¸²è”ç»„ä»¶çš„æ ¸å¿ƒæ–¹å¼ã€‚**

   å½“ç„¶è¿™é‡Œåˆå‡ºçŽ°äº†ä¸€ä¸ªç¼ºç‚¹ï¼Œè¿™å°±è¦å›žåˆ° `Agent` çš„å®šä¹‰ä¸ŠåŽ»äº†ã€‚

   ä»€ä¹ˆæ˜¯ `Agent` , å³ ***An LLM agent runs tools in a loop to achieve a goal***

   key point is ***the loop*** ä½†æ˜¯å…¶ä¸²è¡Œçš„æ–¹å¼æ„å‘³ç€è¿™æ— æ³•è¿›è¡Œè‡ªæ£€å’Œå¾ªçŽ¯ï¼Œè¿™å°±ä¸ç¬¦åˆå…¶å®šä¹‰

   å› æ­¤ `langchain` ä¾¿æŽ¨å‡ºäº† `langgraph`  ä»¥åŠåŽç»­çš„å¤§æ”¹ç‰ˆï¼Œ å½“ç„¶å°±è¿™æ˜¯å…¶ä»–æ¨¡å—è¦è¯´çš„ä¸œè¥¿äº†ã€‚ 

   ** **

4. **å¼‚æ­¥/æµå¼é‡å¤å†™** â†’ åŸºç±»æä¾›é»˜è®¤å®žçŽ°

5. **ç±»åž‹ä¸é€æ˜Ž** â†’ `input_schema`/`output_schema` è‡ªåŠ¨æŽ¨æ–­

---

## ðŸŒŸç¬¬äºŒéƒ¨åˆ†ï¼šä¸€åˆ‡éƒ½æ˜¯Serializableä¹‹RunnableSerializable

~~~python
class RunnableSerializable(Serializable, Runnable[Input, Output]):
    """Runnable that can be serialized to JSON."""

    name: str | None = None
    """The name of the `Runnable`.

    Used for debugging and tracing.
    """

    model_config = ConfigDict(
        # Suppress warnings from pydantic protected namespaces
        # (e.g., `model_`)
        protected_namespaces=(),
    )

    @override
    def to_json(self) -> SerializedConstructor | SerializedNotImplemented:
        """Serialize the `Runnable` to JSON.

        Returns:
            A JSON-serializable representation of the `Runnable`.

        """
        dumped = super().to_json()
        with contextlib.suppress(Exception):
            dumped["name"] = self.get_name()
        return dumped

    def configurable_fields(
        self, **kwargs: AnyConfigurableField
    ) -> RunnableSerializable[Input, Output]:
        """Configure particular `Runnable` fields at runtime.

        Args:
            **kwargs: A dictionary of `ConfigurableField` instances to configure.

        Raises:
            ValueError: If a configuration key is not found in the `Runnable`.

        Returns:
            A new `Runnable` with the fields configured.

        !!! example

            ```python
            from langchain_core.runnables import ConfigurableField
            from langchain_openai import ChatOpenAI

            model = ChatOpenAI(max_tokens=20).configurable_fields(
                max_tokens=ConfigurableField(
                    id="output_token_number",
                    name="Max tokens in the output",
                    description="The maximum number of tokens in the output",
                )
            )

            # max_tokens = 20
            print(
                "max_tokens_20: ", model.invoke("tell me something about chess").content
            )

            # max_tokens = 200
            print(
                "max_tokens_200: ",
                model.with_config(configurable={"output_token_number": 200})
                .invoke("tell me something about chess")
                .content,
            )
            ```
        """
        # Import locally to prevent circular import
        from langchain_core.runnables.configurable import (  # noqa: PLC0415
            RunnableConfigurableFields,
        )

        model_fields = type(self).model_fields
        for key in kwargs:
            if key not in model_fields:
                msg = (
                    f"Configuration key {key} not found in {self}: "
                    f"available keys are {model_fields.keys()}"
                )
                raise ValueError(msg)

        return RunnableConfigurableFields(default=self, fields=kwargs)

    def configurable_alternatives(
        self,
        which: ConfigurableField,
        *,
        default_key: str = "default",
        prefix_keys: bool = False,
        **kwargs: Runnable[Input, Output] | Callable[[], Runnable[Input, Output]],
    ) -> RunnableSerializable[Input, Output]:
        """Configure alternatives for `Runnable` objects that can be set at runtime.

        Args:
            which: The `ConfigurableField` instance that will be used to select the
                alternative.
            default_key: The default key to use if no alternative is selected.
            prefix_keys: Whether to prefix the keys with the `ConfigurableField` id.
            **kwargs: A dictionary of keys to `Runnable` instances or callables that
                return `Runnable` instances.

        Returns:
            A new `Runnable` with the alternatives configured.

        !!! example

            ```python
            from langchain_anthropic import ChatAnthropic
            from langchain_core.runnables.utils import ConfigurableField
            from langchain_openai import ChatOpenAI

            model = ChatAnthropic(
                model_name="claude-sonnet-4-5-20250929"
            ).configurable_alternatives(
                ConfigurableField(id="llm"),
                default_key="anthropic",
                openai=ChatOpenAI(),
            )

            # uses the default model ChatAnthropic
            print(model.invoke("which organization created you?").content)

            # uses ChatOpenAI
            print(
                model.with_config(configurable={"llm": "openai"})
                .invoke("which organization created you?")
                .content
            )
            ```
        """
        # Import locally to prevent circular import
        from langchain_core.runnables.configurable import (  # noqa: PLC0415
            RunnableConfigurableAlternatives,
        )

        return RunnableConfigurableAlternatives(
            which=which,
            default=self,
            alternatives=kwargs,
            default_key=default_key,
            prefix_keys=prefix_keys,
        )

~~~

å…¶æ‰¿è½½çš„æ ¸å¿ƒåŠŸèƒ½å°±æ˜¯Serializeæ‰€æœ‰å¯Serializeçš„Runnableçš„å¯¹è±¡ï¼Œlangchainé‡å†™äº†Serializableï¼Œå¡«å……äº†å…³äºŽlcçš„ä¸€å †å±žæ€§ï¼Œå¦‚ä¸‹

```python
    @property
    def lc_secrets(self) -> dict[str, str]:
        """A map of constructor argument names to secret ids.

        For example, `{"openai_api_key": "OPENAI_API_KEY"}`
        """
        return {}

    @property
    def lc_attributes(self) -> dict:
        """List of attribute names that should be included in the serialized kwargs.

        These attributes must be accepted by the constructor.

        Default is an empty dictionary.
        """
        return {}

    @classmethod
    def lc_id(cls) -> list[str]:
        """Return a unique identifier for this class for serialization purposes.

        The unique identifier is a list of strings that describes the path
        to the object.

        For example, for the class `langchain.llms.openai.OpenAI`, the id is
        `["langchain", "llms", "openai", "OpenAI"]`.
```

ç­‰ç­‰æ–¹æ³•ï¼Œåœ¨langchainä¸­ä¸‡ç‰©çš†å¯¹è±¡ï¼ŒåºŸè¯å…¶å®žï¼Œå¯¹è±¡å°±æœ‰ç‹¬ä¸€æ— äºŒçš„å±žæ€§ã€‚

## ðŸŒŸ ç¬¬ä¸‰éƒ¨åˆ†ï¼šç»„åˆåºåˆ—

### ä¸€ï¼Œ`RunnableSequence` â€” ä¸²è¡Œé“¾ï¼ˆæœ€å¸¸ç”¨ï¼‰

```python
chain = prompt | model | parser
# å†…éƒ¨ï¼šRunnableSequence(first=prompt, middle=[model], last=parser)
# æ‰§è¡Œï¼šprompt çš„è¾“å‡º â†’ model çš„è¾“å…¥ â†’ parser çš„è¾“å…¥
```

`|` æ“ä½œç¬¦å°±æ˜¯ `__or__` é‡è½½ï¼Œè¿”å›žä¸€ä¸ª `RunnableSequence` å¯¹è±¡ã€‚

å› æ­¤ï¼Œå½“Runnableå¯¹è±¡ä½¿ç”¨ `__or__` æ–¹æ³•çš„æ—¶å€™ï¼ŒRunnableå¯¹è±¡è‡ªå·±å°±å˜æˆäº†  `RunnableSequence`

```python
def __or__(
        self,
        other: Runnable[Any, Other]
        | Callable[[Iterator[Any]], Iterator[Other]]
        | Callable[[AsyncIterator[Any]], AsyncIterator[Other]]
        | Callable[[Any], Other]
        | Mapping[str, Runnable[Any, Other] | Callable[[Any], Other] | Any],
    ) -> RunnableSerializable[Input, Other]:
        """Runnable "or" operator.

        Compose this `Runnable` with another object to create a
        `RunnableSequence`.

        Args:
            other: Another `Runnable` or a `Runnable`-like object.

        Returns:
            A new `Runnable`.
        """
        return RunnableSequence(self, coerce_to_runnable(other))
```

è¿™é‡Œ`coerce_to_runnable` ä¼šæŠŠç±»Runnableçš„æ‰€æœ‰ç±»è½¬æˆRunnable, ä¹Ÿæ˜¯ä¸ºäº†ç»Ÿä¸€

### äºŒï¼Œ`RunnableParallel` â€” å¹¶è¡Œé“¾

å®˜æ–¹åœ¨æ³¨é‡Šä¸­å†™æ˜Žäº†

***  ***

***RunnableParallel is one of the two main composition primitives***

å˜›æ„æ€å‘¢ï¼Ÿ

å¤§ç™½è¯å°±æ˜¯ï¼ŒRunnalbeParallelæ˜¯ éžå¸¸é‡è¦ç»„åˆä»¶ä¹‹ä¸€ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯å˜›å‘¢ï¼Œå°±æ˜¯ä¸Šé¢çš„RunnableSequenece 

åœ¨è¿™é‡Œè¯´ä¸‹è¿™ä¸¤ç§æ–¹å¼æœ‰ä½•ä¸åŒ

**æˆ‘ä»¬ä¹‹å‰æåˆ°è¿‡äº†ï¼ŒRunnableSequence æ˜¯ Runnable è°ƒç”¨ or æ–¹æ³•åŽè¿”å›žçš„ç»“æžœï¼Œé‚£ä¹ˆ Sequence ç©¶ç«Ÿäº§ç”Ÿäº†ä¸€ä¸ªä»€ä¹ˆç»“æžœå‘¢ï¼Ÿ**

```python
first: Runnable[Input, Any]
    """The first `Runnable` in the sequence."""
    middle: list[Runnable[Any, Any]] = Field(default_factory=list)
    """The middle `Runnable` in the sequence."""
    last: Runnable[Any, Output]
    """The last `Runnable` in the sequence."""

    def __init__(
        self,
        *steps: RunnableLike,
        name: str | None = None,
        first: Runnable[Any, Any] | None = None,
        middle: list[Runnable[Any, Any]] | None = None,
        last: Runnable[Any, Any] | None = None,
    ) -> None:
        """Create a new `RunnableSequence`.

        Args:
            steps: The steps to include in the sequence.
            name: The name of the `Runnable`.
            first: The first `Runnable` in the sequence.
            middle: The middle `Runnable` objects in the sequence.
            last: The last `Runnable` in the sequence.

        Raises:
            ValueError: If the sequence has less than 2 steps.
        """
        steps_flat: list[Runnable] = []
        if not steps and first is not None and last is not None:
            steps_flat = [first] + (middle or []) + [last]
        for step in steps:
            if isinstance(step, RunnableSequence):
                steps_flat.extend(step.steps)
            else:
                steps_flat.append(coerce_to_runnable(step))
        if len(steps_flat) < _RUNNABLE_SEQUENCE_MIN_STEPS:
            msg = (
                f"RunnableSequence must have at least {_RUNNABLE_SEQUENCE_MIN_STEPS} "
                f"steps, got {len(steps_flat)}"
            )
            raise ValueError(msg)
        super().__init__(
            first=steps_flat[0],
            middle=list(steps_flat[1:-1]),
            last=steps_flat[-1],
            name=name,
        )
```

è¿™é‡Œ RunnableSequence æ–¹æ³•ï¼Œå®šä¹‰äº†ä¸‰ä¸ªå‚æ•°ï¼Œfirstã€middleã€last é¦–å°¾å‚æ•°éƒ½æ˜¯ä¸€ä¸ª Runnable å¯¹è±¡ï¼Œä¸­é—´æ˜¯ä¸€ä¸ª list çš„ Runnable å¯¹è±¡ã€‚

å†ç»“åˆSequenceè¿™ä¸ªæ–¹æ³•åï¼Œæ˜¾è€Œæ˜“è§ï¼Œè¿™æ˜¯ä¸€ä¸ªé¡ºåºçš„é“¾æ¡ï¼Œä¸‹é¢å†çœ‹å…¶æ˜¯å¦‚ä½•æ‹¼æŽ¥çš„

```
        steps_flat: list[Runnable] = []
        if not steps and first is not None and last is not None:
            steps_flat = [first] + (middle or []) + [last]
        for step in steps:
            if isinstance(step, RunnableSequence):
                steps_flat.extend(step.steps)
            else:
                steps_flat.append(coerce_to_runnable(step))
        if len(steps_flat) < _RUNNABLE_SEQUENCE_MIN_STEPS:
            msg = (
                f"RunnableSequence must have at least {_RUNNABLE_SEQUENCE_MIN_STEPS} "
                f"steps, got {len(steps_flat)}"
            )
            raise ValueError(msg)
        super().__init__(
            first=steps_flat[0],
            middle=list(steps_flat[1:-1]),
            last=steps_flat[-1],
            name=name,
        )
```



å…¶ä»–çš„ä¸èµ˜è¿°ï¼Œè¦æ³¨æ„ä¸€ç‚¹ï¼Œå°±æ˜¯å½“ï¼Œstepï¼Œå³ä¸­é—´çš„ä¸€å †å­˜åœ¨æ—¶ï¼Œç›´æŽ¥ä¼šç”¨extendæ–¹æ³•é‡æž„ä¸‹













```python
chain = prompt | {"answer": model, "source": retriever}
# å­—å…¸å­—é¢é‡è‡ªåŠ¨å˜æˆ RunnableParallel
# åŒä¸€ä¸ªè¾“å…¥åŒæ—¶å‘ç»™ model å’Œ retrieverï¼Œç»“æžœåˆæˆä¸€ä¸ª dict
```

### `RunnableLambda` â€” æ™®é€šå‡½æ•°åŒ…è£…å™¨

```python
add_one = RunnableLambda(lambda x: x + 1)
chain = add_one | model  # æ™®é€šå‡½æ•°ä¹Ÿèƒ½å‚ä¸Žé“¾å¼è°ƒç”¨
```

### `RunnableGenerator` â€” ç”Ÿæˆå™¨åŒ…è£…å™¨

```python
def stream_words(input):
    for word in input.split():
        yield word

streamer = RunnableGenerator(stream_words)  # æ”¯æŒæµå¼
```

---

## ðŸŒŸ ç¬¬ä¸‰éƒ¨åˆ†ï¼šaliment of Agent 

### `bind()` â€” Agent ç»‘å®šå·¥å…·çš„åŸºç¡€

```python
model_with_tools = model.bind_tools(tools)
# åº•å±‚å°±æ˜¯ bind()ï¼Œå°†å·¥å…· schema ä½œä¸ºé»˜è®¤å‚æ•°ç»‘å®šåˆ°æ¨¡åž‹ä¸Š
```

### `with_retry()` + `with_fallbacks()` â€” å®¹é”™æœºåˆ¶

```python
safe_model = model.with_retry(stop_after_attempt=3)
safe_model = gpt4.with_fallbacks([gpt35, local_model])
```

### LCEL çš„çŽ°çŠ¶ï¼ˆ2025ï¼‰

LCELï¼ˆ`A | B | C` è¯­æ³•ï¼‰æ²¡æœ‰è¢«åºŸå¼ƒï¼Œä½†å·²**ä»Žå°å‰é€€åˆ°å°åŽ**ï¼š

| å±‚çº§ | ç”¨ä»€ä¹ˆ | è¯´æ˜Ž |
| :--- | :--- | :--- |
| **Agent ç¼–æŽ’å±‚** | **LangGraph** | çŠ¶æ€æœº + å›¾ï¼ˆæ”¯æŒå¾ªçŽ¯å’Œåˆ†æ”¯ï¼‰ |
| **å•æ­¥æ‰§è¡Œå±‚** | **LCEL** | åœ¨ LangGraph èŠ‚ç‚¹å†…éƒ¨ `prompt \| model \| parser` |

LCEL é€‚åˆçº¿æ€§é“¾ï¼Œä½† Agent éœ€è¦å¾ªçŽ¯ï¼ˆæ€è€ƒâ†’è¡ŒåŠ¨â†’è§‚å¯Ÿâ†’å†æ€è€ƒï¼‰ï¼Œè¿™éœ€è¦ LangGraphã€‚

---

## ðŸ”— ç›¸å…³æºç 

- `langchain_core/runnables/base.py` â€” `Runnable` åŠæ‰€æœ‰ç»„åˆåŽŸè¯­çš„å®šä¹‰
- `langchain_core/runnables/config.py` â€” `RunnableConfig` è¿è¡Œæ—¶é…ç½®
